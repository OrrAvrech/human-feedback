import os
import torch
from pathlib import Path
from data.datasets import BaseMotionSplit, BaseMotion
from data.humanml.motion_process import recover_from_ric, extract_features, FID_R, FID_L, FACE_JOINT_INDX
from data.humanml.kinematic_trees import T2M_KINEMATIC_CHAIN, T2M_RAW_OFFSETS
from perturbate.transforms import random_motion_warping, get_smpl_model
from utils.visualize import plot_3d_motion
import numpy as np


def main():
    dataset_dir = Path("/Users/orrav/Documents/Data/HumanML3D/HumanML3D")
    human_feedback_dir = dataset_dir / "human_feedback" / "vecs_11"
    human_feedback_dir.mkdir(exist_ok=True, parents=True)
    smpl_dir = Path("./models/data")
    save_dir = Path("/Users/orrav/Documents/Data/human-feedback/experiments/humanml3d")
    save_dir.mkdir(exist_ok=True, parents=True)
    max_frames = None
    num_joints = 22
    num_iter = 3


    ds = BaseMotionSplit(dataset_dir=dataset_dir,
                         motion_dir="new_joint_vecs",
                         split="train",
                         max_frames=max_frames)
    smpl_model = get_smpl_model(smpl_dir)

    motion = ds[0]
    npy_path = ds.motions_list[0]

    joints = recover_from_ric(motion, num_joints)
    joints_np  = joints.detach().numpy()
    parents = smpl_model.parents[:num_joints]

    saved_files = []
    ani_save_path = save_dir / "input_motion.mp4"
    plot_3d_motion(ani_save_path, T2M_KINEMATIC_CHAIN, joints_np, title="input-motion", fps=30)
    saved_files.append(ani_save_path)

    output_dir = human_feedback_dir / npy_path.stem
    output_dir.mkdir(exist_ok=True)
    for i in range(num_iter):
        posed_joint_positions, pert_frames = random_motion_warping(joints, parents, pert_perc=0.05)
        posed_joints_np = posed_joint_positions.numpy()
        posed_data = extract_features(posed_joints_np, feet_thre=0.002,
                                      n_raw_offsets=torch.from_numpy(T2M_RAW_OFFSETS),
                                      kinematic_chain=T2M_KINEMATIC_CHAIN,
                                      fid_r=FID_R, fid_l=FID_L, face_joint_indx=FACE_JOINT_INDX)
        output_filepath = output_dir / f"{npy_path.stem}_{i}.npy"
        np.save(output_filepath, posed_data)
        print(f"save file {str(output_filepath)}")

        ani_save_path = save_dir / f"humanml3d_posed_{i}.mp4"
        plot_3d_motion(ani_save_path, T2M_KINEMATIC_CHAIN, posed_joints_np, title=f"iter-{i+1}", fps=30,
                       pert_frames=pert_frames)
        saved_files.append(ani_save_path)

    save_file = save_dir / "humanml3d_schema11.mp4"
    ffmpeg_rep_files = [f' -i {str(f)} ' for f in saved_files]
    hstack_args = f' -filter_complex hstack=inputs={len(saved_files)}'
    ffmpeg_rep_cmd = f'ffmpeg -y -loglevel warning ' + ''.join(ffmpeg_rep_files) + f'{hstack_args} {str(save_file)}'
    os.system(ffmpeg_rep_cmd)



if __name__ == "__main__":
    main()